{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dda1726",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57be12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15df2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def get_isins(data):\n",
    "    return data['Isin'].tolist()\n",
    "\n",
    "\n",
    "def concatenate_data(prefixes, isindata, start_date, end_date):\n",
    "    yf.pdr_override()\n",
    "    data_list = []\n",
    "    for prefix in prefixes:\n",
    "        filtered_isin = []\n",
    "        for i in range(0, len(isindata)):\n",
    "            if isindata[i][:len(prefix)] == prefix:\n",
    "                filtered_isin.append(isindata[i])\n",
    "        data = pdr.get_data_yahoo(filtered_isin, start=start_date, end=end_date)\n",
    "        data_list.append(data)\n",
    "    combined_data = pd.concat(data_list, sort=False, axis=1, join='inner')\n",
    "    return combined_data\n",
    "\n",
    "def remove_null_columns(data):\n",
    "    null_columns = []\n",
    "    for col in data.columns:\n",
    "        if data[col].isnull().all():\n",
    "            null_columns.append(col)\n",
    "    return data.drop(columns=null_columns)\n",
    "\n",
    "\n",
    "\n",
    "def filter_by_column(data,stock_data, column_name, column_value=None):\n",
    "    if column_value is not None:\n",
    "        filtered = data[data[column_name] == column_value]\n",
    "        data_isin = get_isins(filtered)\n",
    "        filtered_data = [c for c in stock_data.columns if c in data_isin]\n",
    "        subset = stock_data[filtered_data]\n",
    "        return subset\n",
    "    else:\n",
    "        return stock_data\n",
    "    \n",
    "\n",
    "    \n",
    "def filter_by_value(stock_data, data, column_name, threshold=None, operator=None):\n",
    "    if threshold is not None:\n",
    "        if operator == 'leq':\n",
    "            filtered=data[data[column_name] <= threshold]\n",
    "            data_isin = get_isins(filtered)\n",
    "            filtered_data = [c for c in stock_data.columns if c in data_isin]\n",
    "            subset = stock_data[filtered_data]\n",
    "            return subset\n",
    "\n",
    "        if operator == 'geq':\n",
    "            filtered=data[data[column_name] >= threshold]\n",
    "            data_isin = get_isins(filtered)\n",
    "            filtered_data = [c for c in stock_data.columns if c in data_isin]\n",
    "            subset = stock_data[filtered_data]\n",
    "            return subset\n",
    "\n",
    "        else:\n",
    "            return stock_data\n",
    "    else:\n",
    "        return stock_data\n",
    "    \n",
    "\n",
    "def to_date(data,time='y'):\n",
    "    adj_pct = data.ffill().pct_change()\n",
    "    adj_pct.index = pd.to_datetime(adj_pct.index)\n",
    "    result = adj_pct.resample(time).sum()\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_stock_data(file_path, prefixes, start_date, end_date):\n",
    "    if stock_data not in globals():\n",
    "        data = read_data(file_path)\n",
    "        isins = get_isins(data)\n",
    "        st_data = concatenate_data(prefixes, isins, start_date, end_date)\n",
    "        stock_data = remove_null_columns(st_data)\n",
    "        return stock_data\n",
    "    else:\n",
    "        return stock_data\n",
    "\n",
    "\n",
    "def get_filtered_stock_data(file_path, column_name, column_value, prefixes, start_date, end_date, time='y', threshold=None, operator=None):\n",
    "    global stock_data\n",
    "    \n",
    "    if stock_data not in globals():\n",
    "   \n",
    "        data = read_data(file_path)\n",
    "        \n",
    "        isins = get_isins(data)\n",
    "        \n",
    "        stock_data = concatenate_data(prefixes, isins, start_date, end_date)\n",
    "        \n",
    "        stock_data = remove_null_columns(stock_data)\n",
    "    \n",
    "    stock_data = stock_data['Adj Close']\n",
    "    \n",
    "    if isinstance(threshold, int):\n",
    "            \n",
    "        filtered_data = filter_by_value(stock_data, data, column_name, threshold, operator)\n",
    "            \n",
    "    elif threshold is None:\n",
    "            \n",
    "        filtered_data = filter_by_column(data,stock_data, column_name, column_value)\n",
    "            \n",
    "    formatted_data = to_date(filtered_data, time)\n",
    "    return formatted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed1aefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stock_data = None\n",
    "file_path = \"ESG_DATA.csv\"\n",
    "column_name = 'environment_level'\n",
    "column_value = 'Excellent'\n",
    "threshold = None\n",
    "operator = 'geq'\n",
    "prefixes= ['SE', 'DK','NO']\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2021-04-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c731b92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667384ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  115 of 115 completed\n",
      "\n",
      "10 Failed downloads:\n",
      "- : No timezone found, symbol may be delisted\n",
      "- COLL.ST: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- ARPL.ST: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- JOBS.ST: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- BRILL.ST: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- INT.ST: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- VIVA.ST: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- SFL.ST: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- PURE.ST: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- CTEK.ST: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "[*********************100%***********************]  36 of 36 completed\n",
      "\n",
      "1 Failed download:\n",
      "- : No timezone found, symbol may be delisted\n",
      "[*********************100%***********************]  95 of 95 completed\n",
      "\n",
      "6 Failed downloads:\n",
      "- : No timezone found, symbol may be delisted\n",
      "- NTI.OL: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- DVD.OL: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- ELO.OL: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- GCC.OL: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n",
      "- PNOR.OL: Data doesn't exist for startDate = 1262300400, endDate = 1619733600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SE0011337708</th>\n",
       "      <th>DK0010263722</th>\n",
       "      <th>DK0060094928</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-12-31 00:00:00+01:00</th>\n",
       "      <td>0.233126</td>\n",
       "      <td>-0.301292</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 00:00:00+01:00</th>\n",
       "      <td>0.085138</td>\n",
       "      <td>-0.637522</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 00:00:00+01:00</th>\n",
       "      <td>0.402724</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31 00:00:00+01:00</th>\n",
       "      <td>0.441324</td>\n",
       "      <td>-0.208075</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 00:00:00+01:00</th>\n",
       "      <td>0.042047</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31 00:00:00+01:00</th>\n",
       "      <td>0.447685</td>\n",
       "      <td>-0.089911</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 00:00:00+01:00</th>\n",
       "      <td>-0.009339</td>\n",
       "      <td>0.083899</td>\n",
       "      <td>0.056770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 00:00:00+01:00</th>\n",
       "      <td>0.183381</td>\n",
       "      <td>-0.068273</td>\n",
       "      <td>0.276583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 00:00:00+01:00</th>\n",
       "      <td>0.077873</td>\n",
       "      <td>0.409519</td>\n",
       "      <td>0.299253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 00:00:00+01:00</th>\n",
       "      <td>0.405096</td>\n",
       "      <td>0.448306</td>\n",
       "      <td>0.502530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 00:00:00+01:00</th>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.755178</td>\n",
       "      <td>0.664912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 00:00:00+01:00</th>\n",
       "      <td>0.170958</td>\n",
       "      <td>0.089872</td>\n",
       "      <td>-0.282230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SE0011337708  DK0010263722  DK0060094928\n",
       "Date                                                               \n",
       "2010-12-31 00:00:00+01:00      0.233126     -0.301292      0.000000\n",
       "2011-12-31 00:00:00+01:00      0.085138     -0.637522      0.000000\n",
       "2012-12-31 00:00:00+01:00      0.402724      0.004191      0.000000\n",
       "2013-12-31 00:00:00+01:00      0.441324     -0.208075      0.000000\n",
       "2014-12-31 00:00:00+01:00      0.042047      0.036437      0.000000\n",
       "2015-12-31 00:00:00+01:00      0.447685     -0.089911      0.000000\n",
       "2016-12-31 00:00:00+01:00     -0.009339      0.083899      0.056770\n",
       "2017-12-31 00:00:00+01:00      0.183381     -0.068273      0.276583\n",
       "2018-12-31 00:00:00+01:00      0.077873      0.409519      0.299253\n",
       "2019-12-31 00:00:00+01:00      0.405096      0.448306      0.502530\n",
       "2020-12-31 00:00:00+01:00      0.020207      0.755178      0.664912\n",
       "2021-12-31 00:00:00+01:00      0.170958      0.089872     -0.282230"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = get_filtered_stock_data(file_path, column_name, column_value, prefixes, start_date, end_date, time='y', threshold=threshold, operator=operator)\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(file_path)\n",
    "isins = get_isins(data)\n",
    "stock_data = concatenate_data(prefixes, isins, start_date, end_date)\n",
    "stock_data = remove_null_columns(stock_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
